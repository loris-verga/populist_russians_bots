{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importation of packages",
   "id": "4b8e8d93ae471610"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:16:56.123296Z",
     "start_time": "2024-06-13T13:16:56.120599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import csv"
   ],
   "id": "80f5fcd342a07907",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definition of time constants \n",
   "id": "ddfc0e88536dab11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:16:57.097359Z",
     "start_time": "2024-06-13T13:16:57.095346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "START_DATE = np.datetime64('2014-07-01')\n",
    "END_DATE = np.datetime64('2018-06-01')\n"
   ],
   "id": "ec0614fa7500e344",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Filter the data : \n",
    "- Keep only tweets written in english \n",
    "- Remove links in the tweets\n",
    "- Remove columns that we do not need \n",
    "- Reformat dates"
   ],
   "id": "c6c43b8cc99412e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:11:23.392853Z",
     "start_time": "2024-06-13T13:10:50.496120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from filter_data import * \n",
    "\n",
    "#Call the function with the input file name and column indices\n",
    "for i in range(1, 14): \n",
    "    input_path= \"./data/original_data/IRAhandle_tweets_{}.csv\".format(i)\n",
    "    output_path= \"./data/filtered_data/IRAhandle_tweets_{}.csv\".format(i)\n",
    "    filter_csv(input_path, output_path, column_indices, 4, \"English\")\n",
    "    extract_date_columns(output_path, output_path)\n",
    "    remove_links(output_path, output_path)"
   ],
   "id": "2135a4bb255d1789",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5c572ba69b498106"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the date array ",
   "id": "5c6b487c045a5144"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:16:59.440553Z",
     "start_time": "2024-06-13T13:16:59.437607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_date_array(): \n",
    "    # Calculate the number of days between start and end dates\n",
    "    num_days = (END_DATE - START_DATE).astype(int) + 1\n",
    "    \n",
    "    # Create an array of timedelta objects representing each day\n",
    "    timedelta_array = np.arange(num_days)\n",
    "    \n",
    "    # Convert timedelta array to datetime array by adding it to start date\n",
    "    date_array = START_DATE + timedelta_array * np.timedelta64(1, 'D')\n",
    "    \n",
    "    return date_array"
   ],
   "id": "afa47f9dfd691d08",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now plot the number of tweets accross time of our dataset",
   "id": "dc7cd0a923e1143e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:11:42.943109Z",
     "start_time": "2024-06-13T13:11:31.087241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "# Number of tweets per day\n",
    "def get_number_of_tweet_each_day(input_file, date_array): \n",
    "\n",
    "\n",
    "    number_of_tweets_per_day = np.zeros(date_array.shape)\n",
    "    \n",
    "    \n",
    "    # Open the input file for reading\n",
    "    with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        # Read the header\n",
    "        header = next(reader)\n",
    "        \n",
    "        # Process each row in the input file\n",
    "        for row in reader:\n",
    "            year = int(row[3])\n",
    "            month = int(row[4])\n",
    "            day = int(row[5])\n",
    "            date = datetime.date(year, month, day)\n",
    "            numpy_date = np.datetime64(date)\n",
    "\n",
    "\n",
    "            # find the index of the date in the date_range\n",
    "            index = np.where(date_array == numpy_date)\n",
    "\n",
    "            # Increment the number of tweets for that day\n",
    "            number_of_tweets_per_day[index] += 1  \n",
    "        \n",
    "        return number_of_tweets_per_day\n",
    "           \n",
    "# print(date_array)\n",
    "\n",
    "date_array = get_date_array()\n",
    "\n",
    "print(date_array.shape)\n",
    "print(np.where(date_array == \"2018-01-01\"))\n",
    "number_of_tweets_per_day= np.zeros(date_array.shape)\n",
    "\n",
    "for i in range(1, 14):\n",
    "    number_of_tweets_per_day += get_number_of_tweet_each_day(\"./data/filtered_data/IRAhandle_tweets_\" + str(i) + \".csv\", date_array)\n",
    "\n",
    "print(np.sum(number_of_tweets_per_day, axis=0))\n",
    "%matplotlib qt\n",
    "\n",
    "plt.plot(date_array, number_of_tweets_per_day)\n",
    "plt.show()\n"
   ],
   "id": "83ecdb6948739df2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1432,)\n",
      "(array([], dtype=int64),)\n",
      "2116719.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "MESA-LOADER: failed to open iris: /usr/lib/dri/iris_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "failed to load driver: iris\n",
      "MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3ccca3b8c3e11ca0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Free memory",
   "id": "9bdf686489267793"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T12:16:05.132209Z",
     "start_time": "2024-06-13T12:16:05.096324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "del number_of_tweets_per_day\n",
    "del date_array\n",
    "gc.collect()"
   ],
   "id": "c1e752826ba69969",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3269"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Function contains ",
   "id": "9b55f47ef3e5bfc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:12:46.369917Z",
     "start_time": "2024-06-13T13:12:46.367598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def contains_any_word(text, word_set):\n",
    "    text_words = set(text.split())\n",
    "    return not text_words.isdisjoint(word_set)"
   ],
   "id": "acd3a83a695ba073",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Single file dictionary based statistics",
   "id": "2cb274dcc43a9622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:19:51.714442Z",
     "start_time": "2024-06-13T13:19:51.709791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_number_of_tweets_per_day_with_at_least_one_word(input_file, dictionary, date_array): \n",
    "    \n",
    "    nb_of_tweets_per_day_positive = np.zeros(date_array.shape)\n",
    "    \n",
    "    # Open the input file for reading\n",
    "    with open(input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        \n",
    "        \n",
    "        # Read the header\n",
    "        header = next(reader)\n",
    "        \n",
    "        # Process each row in the input file\n",
    "        for row in reader:\n",
    "            \n",
    "            text = row[1]\n",
    "            \n",
    "            if contains_any_word(text, dictionary): \n",
    "                \n",
    "                year = int(row[3])\n",
    "                month = int(row[4])\n",
    "                day = int(row[5])\n",
    "                date = datetime.date(year, month, day)\n",
    "                numpy_date = np.datetime64(date)\n",
    "                \n",
    "    \n",
    "                # find the index of the date in the date_range\n",
    "                index = np.where(date_array == numpy_date)\n",
    "    \n",
    "                # Increment the number of tweets for that day\n",
    "                nb_of_tweets_per_day_positive[index] += 1  \n",
    "                \n",
    "    return nb_of_tweets_per_day_positive\n",
    "    "
   ],
   "id": "aa751acf96d7d24a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test function ",
   "id": "6aa8c046f3f42732"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T13:36:34.887664Z",
     "start_time": "2024-06-13T13:36:34.370532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "date_array = get_date_array()\n",
    "dictionary = {\"Hi\"}\n",
    "nb = get_number_of_tweets_per_day_with_at_least_one_word(\"./data/filtered_data/IRAhandle_tweets_1.csv\",dictionary, date_array)\n",
    "print(np.sum(nb))\n",
    "plt.plot(date_array, nb)\n",
    "plt.show()\n",
    "\n",
    "del date_array\n",
    "del nb\n",
    "gc.collect()"
   ],
   "id": "ec39a93763301017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23469"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analysis on all files \n",
   "id": "f2dec290bfe1f340"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:07:06.093559Z",
     "start_time": "2024-06-13T14:07:06.090517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def all_files_analysis(dictionary, date_array): \n",
    "    nb = np.zeros(date_array.shape)\n",
    "    for i in range(1, 14): \n",
    "        nb += get_number_of_tweets_per_day_with_at_least_one_word(\"./data/filtered_data/IRAhandle_tweets_{}.csv\".format(i),dictionary , date_array)\n",
    "    return nb\n"
   ],
   "id": "9a2d809afda25dd1",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test",
   "id": "f21abce58ab72511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:07:11.695410Z",
     "start_time": "2024-06-13T14:07:07.768369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "date_array= get_date_array()\n",
    "dictionary = {\"Hi\"}\n",
    "nb = all_files_analysis(dictionary, date_array)\n",
    "\n",
    "plt.plot(date_array, nb)\n",
    "plt.show()\n",
    "print(np.sum(nb, axis=0))\n",
    "del nb\n",
    "del date_array\n",
    "gc.collect()"
   ],
   "id": "18431e3562cb928",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parallel version",
   "id": "ea03e9a816ce5092"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:07:42.761448Z",
     "start_time": "2024-06-13T14:07:42.758608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import concurrent.futures\n",
    "def analyze_file(file_index, dictionary, date_array):\n",
    "    file_path = f\"./data/filtered_data/IRAhandle_tweets_{file_index}.csv\"\n",
    "    return get_number_of_tweets_per_day_with_at_least_one_word(file_path, dictionary, date_array)\n",
    "\n",
    "def all_files_analysis_par(dictionary, date_array):\n",
    "    nb = np.zeros(date_array.shape)\n",
    "    file_indices = range(1, 14)  \n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(analyze_file, i, dictionary, date_array) for i in file_indices]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            nb += future.result()\n",
    "\n",
    "    return nb\n",
    "\n"
   ],
   "id": "64fee7165827dda8",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test\n",
   "id": "a29b5751b7d777a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:07:48.237997Z",
     "start_time": "2024-06-13T14:07:44.037082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "date_array= get_date_array()\n",
    "dictionary = {\"Hi\"}\n",
    "nb = all_files_analysis_par(dictionary, date_array)\n",
    "plt.plot(date_array, nb)\n",
    "plt.show()\n",
    "print(np.sum(nb, axis=0))\n",
    "del nb\n",
    "del date_array\n",
    "gc.collect()"
   ],
   "id": "6e5e36abbf8acb44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2987"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
